{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"N4fycXYxsIP1","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1758183875374,"user_tz":-330,"elapsed":30090,"user":{"displayName":"beach safety major project","userId":"04819698429459369921"}},"outputId":"0dcb1983-900b-44ba-c99d-33ac8bd975db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n","Collecting onnx\n","  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n","Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n","Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n","Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.3)\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.2.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.13.3)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: humanfriendly, onnx, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.19.0 onnxruntime-1.22.1\n","âš¡ Using device: cuda\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/dataset/train/images'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3023753107.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Dataset + DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSegmentationDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_IMG_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_MASK_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0mvalid_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSegmentationDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVALID_IMG_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVALID_MASK_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3023753107.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_dir, mask_dir, img_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/dataset/train/images'"]}],"source":["!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n","!pip install onnx onnxruntime\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","from PIL import Image\n","import numpy as np\n","\n","# ---------------- CONFIG ---------------- #\n","TRAIN_IMG_DIR = \"/content/drive/MyDrive/dataset/train/images\"\n","TRAIN_MASK_DIR = \"/content/drive/MyDrive/dataset/train/masks\"\n","VALID_IMG_DIR = \"/content/drive/MyDrive/dataset/valid/images\"\n","VALID_MASK_DIR = \"/content/drive/MyDrive/dataset/valid/masks\"\n","\n","NUM_CLASSES = 3  # background + 3 classes\n","IMG_SIZE = 640\n","BATCH_SIZE = 4\n","EPOCHS = 40\n","LR = 1e-3\n","\n","# Device selection: prioritize MPS â†’ CUDA â†’ CPU\n","if torch.backends.mps.is_available():\n","    DEVICE = \"mps\"\n","elif torch.cuda.is_available():\n","    DEVICE = \"cuda\"\n","else:\n","    DEVICE = \"cpu\"\n","\n","print(f\"âš¡ Using device: {DEVICE}\")\n","\n","\n","# ---------------- Dataset ---------------- #\n","class SegmentationDataset(Dataset):\n","    def __init__(self, img_dir, mask_dir, img_size=640):\n","        self.img_dir = img_dir\n","        self.mask_dir = mask_dir\n","        self.images = os.listdir(img_dir)\n","        self.img_size = img_size\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.images[idx])\n","        mask_path = os.path.join(self.mask_dir, self.images[idx].replace('.jpg', '.png'))\n","\n","        # Open\n","        image = Image.open(img_path).convert(\"RGB\")\n","        mask = Image.open(mask_path).convert(\"L\")\n","\n","        # âœ… Resize to fixed 640x640\n","        image = image.resize((self.img_size, self.img_size), Image.BILINEAR)\n","        mask = mask.resize((self.img_size, self.img_size), Image.NEAREST)\n","\n","        # Convert to tensors\n","        image = transforms.ToTensor()(image)  # [C, H, W]\n","        mask = torch.from_numpy(np.array(mask, dtype=np.int64))  # [H, W]\n","\n","        return image, mask\n","\n","\n","# Dataset + DataLoader\n","train_dataset = SegmentationDataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, img_size=IMG_SIZE)\n","valid_dataset = SegmentationDataset(VALID_IMG_DIR, VALID_MASK_DIR, img_size=IMG_SIZE)\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","\n","# ---------------- U-Net Model ---------------- #\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DoubleConv, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","\n","class UNet(nn.Module):\n","    def __init__(self, n_classes):\n","        super(UNet, self).__init__()\n","        self.enc1 = DoubleConv(3, 64)\n","        self.enc2 = DoubleConv(64, 128)\n","        self.enc3 = DoubleConv(128, 256)\n","        self.enc4 = DoubleConv(256, 512)\n","\n","        self.pool = nn.MaxPool2d(2)\n","        self.bottleneck = DoubleConv(512, 1024)\n","\n","        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n","        self.dec4 = DoubleConv(1024, 512)\n","        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n","        self.dec3 = DoubleConv(512, 256)\n","        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n","        self.dec2 = DoubleConv(256, 128)\n","        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n","        self.dec1 = DoubleConv(128, 64)\n","\n","        self.out = nn.Conv2d(64, n_classes, 1)\n","\n","    def forward(self, x):\n","        e1 = self.enc1(x)\n","        e2 = self.enc2(self.pool(e1))\n","        e3 = self.enc3(self.pool(e2))\n","        e4 = self.enc4(self.pool(e3))\n","        b = self.bottleneck(self.pool(e4))\n","\n","        d4 = self.up4(b)\n","        d4 = self.dec4(torch.cat([d4, e4], dim=1))\n","        d3 = self.up3(d4)\n","        d3 = self.dec3(torch.cat([d3, e3], dim=1))\n","        d2 = self.up2(d3)\n","        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n","        d1 = self.up1(d2)\n","        d1 = self.dec1(torch.cat([d1, e1], dim=1))\n","\n","        return self.out(d1)  # logits\n","\n","\n","# ---------------- Metrics ---------------- #\n","def dice_score(pred, target, num_classes):\n","    pred = torch.argmax(pred, dim=1)\n","    dice = 0\n","    for cls in range(num_classes):\n","        pred_cls = (pred == cls).float()\n","        target_cls = (target == cls).float()\n","        intersection = (pred_cls * target_cls).sum()\n","        union = pred_cls.sum() + target_cls.sum()\n","        if union.item() > 0:\n","            dice += (2. * intersection) / union\n","    return dice / num_classes\n","\n","\n","def iou_score(pred, target, num_classes):\n","    pred = torch.argmax(pred, dim=1)\n","    iou = 0\n","    for cls in range(num_classes):\n","        pred_cls = (pred == cls).float()\n","        target_cls = (target == cls).float()\n","        intersection = (pred_cls * target_cls).sum()\n","        union = pred_cls.sum() + target_cls.sum() - intersection\n","        if union.item() > 0:\n","            iou += intersection / union\n","    return iou / num_classes\n","\n","\n","# ---------------- Training ---------------- #\n","model = UNet(n_classes=NUM_CLASSES).to(DEVICE)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=LR)\n","\n","best_dice = 0.0\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    train_loss = 0\n","    for imgs, masks in train_loader:\n","        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n","\n","        optimizer.zero_grad()\n","        outputs = model(imgs)\n","        loss = criterion(outputs, masks)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","\n","    # Validation\n","    model.eval()\n","    val_loss, val_dice, val_iou = 0, 0, 0\n","    with torch.no_grad():\n","        for imgs, masks in valid_loader:\n","            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n","            outputs = model(imgs)\n","            loss = criterion(outputs, masks)\n","            val_loss += loss.item()\n","            val_dice += dice_score(outputs, masks, NUM_CLASSES)\n","            val_iou += iou_score(outputs, masks, NUM_CLASSES)\n","\n","    val_dice /= len(valid_loader)\n","    val_iou /= len(valid_loader)\n","\n","    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n","          f\"Train Loss: {train_loss/len(train_loader):.4f} | \"\n","          f\"Val Loss: {val_loss/len(valid_loader):.4f} | \"\n","          f\"Dice: {val_dice:.4f} | \"\n","          f\"IoU: {val_iou:.4f}\")\n","\n","    # Save best model\n","    if val_dice > best_dice:\n","        best_dice = val_dice\n","        torch.save(model.state_dict(), \"unet_arecanut_best.pth\")\n","        print(\"ğŸ’¾ Best model updated!\")\n","\n","# Save final model\n","torch.save(model.state_dict(), \"unet_arecanut_final.pth\")\n","print(\"âœ… Training finished. Final model saved.\")\n","\n","# ---------------- Export to ONNX ---------------- #\n","model = UNet(n_classes=NUM_CLASSES).to(DEVICE)\n","model.load_state_dict(torch.load(\"unet_arecanut_final.pth\", map_location=DEVICE))\n","model.eval()\n","\n","dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE, device=DEVICE)\n","onnx_path = \"unet_arecanut.onnx\"\n","\n","torch.onnx.export(\n","    model,\n","    dummy_input,\n","    onnx_path,\n","    export_params=True,\n","    opset_version=11,\n","    do_constant_folding=True,\n","    input_names=[\"input\"],\n","    output_names=[\"output\"],\n","    dynamic_axes={\n","        \"input\": {0: \"batch_size\", 2: \"height\", 3: \"width\"},\n","        \"output\": {0: \"batch_size\", 2: \"height\", 3: \"width\"},\n","    }\n",")\n","\n","print(f\"âœ… ONNX model saved as {onnx_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":30399,"status":"aborted","timestamp":1758183875404,"user":{"displayName":"beach safety major project","userId":"04819698429459369921"},"user_tz":-330},"id":"Z92cr87gtfw9"},"outputs":[],"source":["import os\n","import re\n","\n","folder = \"/content/drive/MyDrive/data ready/train/train_masks_class\"  # change if needed\n","\n","for filename in sorted(os.listdir(folder)):\n","    if filename.lower().endswith((\".png\")):\n","        # Match \"img_<number>_jpg.rf.<random>.jpg\"\n","        match = re.match(r\"(\\d)\\_id.png\", filename)\n","        print(match)\n","        print(match.group(1))\n","        # if match:\n","        #     old_path = os.path.join(folder, filename)\n","        #     new_name = f\"{match.group(1)}.jpg\"\n","        #     new_path = os.path.join(folder, new_name)\n","\n","        #     if not os.path.exists(new_path):  # prevent overwrite\n","        #         os.rename(old_path, new_path)\n","        #         print(f\"Renamed: {filename} -> {new_name}\")\n","        #     else:\n","        #         print(f\"Skipped (already exists):Â {new_name}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyPY790FJLbQ5DUipGS2Cip0"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}